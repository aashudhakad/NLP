{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaN9b4mz2jOA",
        "outputId": "5ffb1e3e-c979-4059-fc73-f4f049e1e3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize #q1\n",
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "text = \"\"\"Natural Language Processing is a field of Artificial Intelligence\n",
        "that focuses on making computers understand human language.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Remove punctuation\n",
        "tokens = [w for w in tokens if w not in string.punctuation]\n",
        "\n",
        "freq_dist = Counter(tokens)\n",
        "\n",
        "print(\"Word Frequency Distribution:\\n\")\n",
        "for word, freq in freq_dist.items():\n",
        "    print(word, \":\", freq)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NUfTkFm6h5R",
        "outputId": "2609a3b3-6479-446d-c4a3-62fd1fcd73fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequency Distribution:\n",
            "\n",
            "natural : 1\n",
            "language : 2\n",
            "processing : 1\n",
            "is : 1\n",
            "a : 1\n",
            "field : 1\n",
            "of : 1\n",
            "artificial : 1\n",
            "intelligence : 1\n",
            "that : 1\n",
            "focuses : 1\n",
            "on : 1\n",
            "making : 1\n",
            "computers : 1\n",
            "understand : 1\n",
            "human : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet #2\n",
        "\n",
        "word = \"good\"\n",
        "\n",
        "synonyms = set()\n",
        "antonyms = set()\n",
        "\n",
        "for syn in wordnet.synsets(word):\n",
        "    for lemma in syn.lemmas():\n",
        "        synonyms.add(lemma.name())\n",
        "        if lemma.antonyms():\n",
        "            antonyms.add(lemma.antonyms()[0].name())\n",
        "\n",
        "print(\"Word:\", word)\n",
        "print(\"Synonyms:\", synonyms)\n",
        "print(\"Antonyms:\", antonyms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqjRVAdJ7Ivh",
        "outputId": "5100e714-cf8d-43c7-9591-a0fb2b094099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: good\n",
            "Synonyms: {'salutary', 'respectable', 'full', 'honorable', 'proficient', 'in_effect', 'effective', 'undecomposed', 'adept', 'soundly', 'safe', 'beneficial', 'commodity', 'upright', 'estimable', 'skilful', 'sound', 'ripe', 'well', 'near', 'practiced', 'unspoiled', 'good', 'unspoilt', 'trade_good', 'just', 'right', 'expert', 'dependable', 'skillful', 'honest', 'thoroughly', 'in_force', 'dear', 'goodness', 'serious', 'secure'}\n",
            "Antonyms: {'evil', 'ill', 'bad', 'evilness', 'badness'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch #3\n",
        "\n",
        "# Create random tensor of size (5,3)\n",
        "tensor = torch.rand(5, 3)\n",
        "print(\"Tensor:\\n\", tensor)\n",
        "\n",
        "# Print shape\n",
        "print(\"\\nShape of tensor:\", tensor.shape)\n",
        "\n",
        "# Mathematical operation (addition)\n",
        "tensor_add = tensor + 2\n",
        "print(\"\\nTensor after addition:\\n\", tensor_add)\n",
        "\n",
        "# Sum of all elements\n",
        "total_sum = torch.sum(tensor)\n",
        "print(\"\\nSum of all elements:\", total_sum.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pMDRCo07O4r",
        "outputId": "f0bdb1d8-905f-41c2-95cd-dcf800584fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:\n",
            " tensor([[0.1760, 0.3362, 0.4485],\n",
            "        [0.0722, 0.0252, 0.5612],\n",
            "        [0.7085, 0.0489, 0.9842],\n",
            "        [0.9646, 0.7597, 0.4306],\n",
            "        [0.2273, 0.7826, 0.0059]])\n",
            "\n",
            "Shape of tensor: torch.Size([5, 3])\n",
            "\n",
            "Tensor after addition:\n",
            " tensor([[2.1760, 2.3362, 2.4485],\n",
            "        [2.0722, 2.0252, 2.5612],\n",
            "        [2.7085, 2.0489, 2.9842],\n",
            "        [2.9646, 2.7597, 2.4306],\n",
            "        [2.2273, 2.7826, 2.0059]])\n",
            "\n",
            "Sum of all elements: 6.531671524047852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create 1D tensor from 10 to 19\n",
        "t1 = torch.arange(10, 20)\n",
        "print(\"1D Tensor:\", t1)\n",
        "\n",
        "# First, last, middle elements\n",
        "print(\"First element:\", t1[0])\n",
        "print(\"Last element:\", t1[-1])\n",
        "print(\"Middle elements:\", t1[4:6])\n",
        "\n",
        "# Create 2D tensor (3x4)\n",
        "t2 = torch.arange(1, 13).reshape(3, 4)\n",
        "print(\"\\n2D Tensor:\\n\", t2)\n",
        "\n",
        "# Extract first row\n",
        "print(\"\\nFirst Row:\", t2[0])\n",
        "\n",
        "# Extract last column\n",
        "print(\"Last Column:\", t2[:, -1])\n",
        "\n",
        "# Extract 2x2 submatrix\n",
        "print(\"2x2 Submatrix:\\n\", t2[0:2, 0:2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECPLZ9MA7WPS",
        "outputId": "a9387277-0ffc-41dc-f317-bc721e3236a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D Tensor: tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])\n",
            "First element: tensor(10)\n",
            "Last element: tensor(19)\n",
            "Middle elements: tensor([14, 15])\n",
            "\n",
            "2D Tensor:\n",
            " tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "\n",
            "First Row: tensor([1, 2, 3, 4])\n",
            "Last Column: tensor([ 4,  8, 12])\n",
            "2x2 Submatrix:\n",
            " tensor([[1, 2],\n",
            "        [5, 6]])\n"
          ]
        }
      ]
    }
  ]
}