{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_XSEdq2xf2N",
        "outputId": "a06cfdc6-09e4-4d5b-d3fa-aafae823847e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Sentences:\n",
            "['\\nNatural Language Processing (NLP) is a branch of Artificial Intelligence that focuses on the interaction\\nbetween computers and humans using natural language.', 'NLP techniques are widely used in applications\\nsuch as chatbots, machine translation, sentiment analysis, and information retrieval.', 'By using libraries like\\nNLTK, developers can tokenize text, remove stopwords, and analyze linguistic patterns efficiently.', 'As data\\ngrows rapidly, NLP plays a crucial role in extracting meaningful insights from unstructured text data.']\n",
            "\n",
            "2) Words:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'branch', 'of', 'Artificial', 'Intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'using', 'natural', 'language', '.', 'NLP', 'techniques', 'are', 'widely', 'used', 'in', 'applications', 'such', 'as', 'chatbots', ',', 'machine', 'translation', ',', 'sentiment', 'analysis', ',', 'and', 'information', 'retrieval', '.', 'By', 'using', 'libraries', 'like', 'NLTK', ',', 'developers', 'can', 'tokenize', 'text', ',', 'remove', 'stopwords', ',', 'and', 'analyze', 'linguistic', 'patterns', 'efficiently', '.', 'As', 'data', 'grows', 'rapidly', ',', 'NLP', 'plays', 'a', 'crucial', 'role', 'in', 'extracting', 'meaningful', 'insights', 'from', 'unstructured', 'text', 'data', '.']\n",
            "\n",
            "3–5) Cleaned Words:\n",
            "['natural', 'language', 'processing', 'nlp', 'branch', 'artificial', 'intelligence', 'focuses', 'interaction', 'computers', 'humans', 'using', 'natural', 'language', 'nlp', 'techniques', 'widely', 'used', 'applications', 'chatbots', 'machine', 'translation', 'sentiment', 'analysis', 'information', 'retrieval', 'using', 'libraries', 'like', 'nltk', 'developers', 'tokenize', 'text', 'remove', 'stopwords', 'analyze', 'linguistic', 'patterns', 'efficiently', 'data', 'grows', 'rapidly', 'nlp', 'plays', 'crucial', 'role', 'extracting', 'meaningful', 'insights', 'unstructured', 'text', 'data']\n",
            "\n",
            "6) Total remaining words: 52\n",
            "\n",
            "7) Top 10 most frequent words:\n",
            "nlp : 3\n",
            "natural : 2\n",
            "language : 2\n",
            "using : 2\n",
            "text : 2\n",
            "data : 2\n",
            "processing : 1\n",
            "branch : 1\n",
            "artificial : 1\n",
            "intelligence : 1\n"
          ]
        }
      ],
      "source": [
        "# Install NLTK (if not already installed)\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Download required NLTK data (run once)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# ------------------ Corpus ------------------\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a branch of Artificial Intelligence that focuses on the interaction\n",
        "between computers and humans using natural language. NLP techniques are widely used in applications\n",
        "such as chatbots, machine translation, sentiment analysis, and information retrieval. By using libraries like\n",
        "NLTK, developers can tokenize text, remove stopwords, and analyze linguistic patterns efficiently. As data\n",
        "grows rapidly, NLP plays a crucial role in extracting meaningful insights from unstructured text data.\n",
        "\"\"\"\n",
        "\n",
        "# ------------------ Task 1 ------------------\n",
        "# Tokenize paragraph into sentences\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"1) Sentences:\")\n",
        "print(sentences)\n",
        "\n",
        "# ------------------ Task 2 ------------------\n",
        "# Tokenize each sentence into words\n",
        "words = []\n",
        "for sentence in sentences:\n",
        "    words.extend(word_tokenize(sentence))\n",
        "\n",
        "print(\"\\n2) Words:\")\n",
        "print(words)\n",
        "\n",
        "# ------------------ Task 3 ------------------\n",
        "# Convert all words to lowercase\n",
        "words = [word.lower() for word in words]\n",
        "\n",
        "# ------------------ Task 4 ------------------\n",
        "# Remove punctuation\n",
        "words = [word for word in words if word not in string.punctuation]\n",
        "\n",
        "# ------------------ Task 5 ------------------\n",
        "# Remove English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "print(\"\\n3–5) Cleaned Words:\")\n",
        "print(filtered_words)\n",
        "\n",
        "# ------------------ Task 6 ------------------\n",
        "# Count total number of remaining words\n",
        "print(\"\\n6) Total remaining words:\", len(filtered_words))\n",
        "\n",
        "# ------------------ Task 7 ------------------\n",
        "# Top 10 most frequent words\n",
        "freq = Counter(filtered_words)\n",
        "top10 = freq.most_common(10)\n",
        "\n",
        "print(\"\\n7) Top 10 most frequent words:\")\n",
        "for word, count in top10:\n",
        "    print(f\"{word} : {count}\")"
      ]
    }
  ]
}